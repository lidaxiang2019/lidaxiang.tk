---
layout: post
title:  "High-Performance Architecture"
rootCate: "work"
categories:
- Web_BackEnd
tags:
- work
- web_backEnd  
- high-performance
- architecture
---

总结高性能架构有关的基础概念，总结多种实现方法。
<!---more--->

> StartTime: 2018-10-12,ModifyTime: 2018-11-23

## 概念名词
1. 并发：同时访问服务器站点的连接数
2. QPS：每秒请求数
QPS（TPS）= 并发数/平均响应时间  一个系统吞吐量通常由QPS（TPS）、并发数两个因素决定
4. 一般的做法是把每天访问系统用户数的10%作为平均的并发用户数。最大的并发用户数乘上一个值，2或者3.
5. 单个reqeust 对CPU消耗越高，外部系统接口、IO影响速度越慢，系统吞吐能力越低，反之越高。  
系统吞吐量几个重要参数：QPS（TPS）、并发数、响应时间
+ QPS（TPS）：每秒钟request/事务 数量
+ 并发数： 系统同时处理的request/事务数
+ 响应时间：  一般取平均响应时间

6. 系统一次调用的响应时间跟项目计划一样，也有一条关键路径，这个关键路径是就是系统影响时间；

7. 通常境况下，我们面对需求，我们评估出来的出来QPS、并发数之外，还有另外一个维度：日PV。  
通过观察系统的访问日志发现，在用户量很大的情况下，各个时间周期内的同一时间段的访问流量几乎一样。比如工作日的每天早上。只要能拿到日流量图和QPS我们就可以推算日流量。

## 测试范围
举例：
双十一，交易峰值32.5万笔/秒，支付峰值25.6万笔/秒。数据库处理峰值4200万/秒。背后是上万台机器。（24核，64G）

我们来粗略计算一下：
```
交易峰值  32.5万笔/秒，按1万台机器算，平均一台机器支撑32.5用户请求
支付峰值25.6万笔/秒，按1万台机器算，平均一台机器支撑25.6用户请求
数据库处理峰值4200万/秒，按1万台机器算，一台机器4200请求（不清楚数据库处理是否都指请求，我们姑且按最大量计算）
一台24核，64G的服务器，也不过才最大支撑4200个请求。
假设我们的测试服务器配置未4核8G内存，效率1/6，每秒请求700请求/S
这样看来，你好意思要求你的服务器并发能达到上万级别吗？？？
```

但估计这里的峰值是指并行，真正同时正在发生的交易，而不是在线用户挂在那里不做操作或者是差零点几秒的操作，这种状况是一般企业少见的极限。

## 参考资料
[性能测试中的并发量概念](https://blog.csdn.net/duzilonglove/article/details/78616167)
